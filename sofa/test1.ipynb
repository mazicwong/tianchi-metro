{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测文言文还是现代文\n",
    "```\n",
    "train: [0: 5000）\n",
    "test: [5000,8385)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('data/train.txt')\n",
    "test = pd.read_csv('data/test.txt')\n",
    "submit = pd.read_csv('data/sample_submit.csv')\n",
    "sample_submit = pd.read_csv('data/sample_submit.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(train) + len(test)\n",
    "n_train = len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 当场训练w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "texts = list(train['text']) + list(test['text'])\n",
    "ndims = 100\n",
    "model = Word2Vec(sentences=texts, size=ndims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用w2v将所有句子加和平均，做嵌入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "vecs = np.zeros([total, ndims])\n",
    "for i, sentence in enumerate(texts):\n",
    "    counts, row = 0, 0\n",
    "    for char in sentence:\n",
    "        try:\n",
    "            if char != ' ':\n",
    "                row += model.wv[char]\n",
    "                counts += 1\n",
    "        except:\n",
    "            pass\n",
    "    if counts == 0:\n",
    "        print(sentence)\n",
    "    vecs[i, :] = row / counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用xbg的分类器做预测(这里也可以用sklearn中的决策树来做)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9456\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "clf = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=1000,\n",
    "    max_depth=4,\n",
    "    min_child_weight=5,\n",
    "    seed=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.3,\n",
    "    gamma=0.5,\n",
    "    reg_alpha=3,\n",
    "    reg_lambda=1,\n",
    "    metrics='logloss')\n",
    "\n",
    "clf.fit(vecs[:n_train], train['y'])\n",
    "print(clf.score(vecs[:n_train], train['y']))\n",
    "submit['y'] = clf.predict_proba(vecs[n_train:])[:, 1]\n",
    "submit.to_csv('my_prediction.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网格搜索调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def model_cv(X_train, Y_train):\n",
    "    cv_params = {\n",
    "        'n_estimators': range(1000, 1050, 25),\n",
    "        # 'max_depth': range(3, 8, 1),\n",
    "        # 'min_child_weight': range(3, 8, 1),\n",
    "        # 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "        # 'colsample_bytree': [0.2, 0.3, 0.4],\n",
    "        # 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6],\n",
    "        # 'reg_alpha': [2, 3, 4, 5, 6],\n",
    "        # 'reg_lambda': [2, 3, 4, 5, 6, 7],\n",
    "        # 'learning_rate': [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "    }\n",
    "    model = xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        learning_rate=0.01,\n",
    "        n_estimators=1000,\n",
    "        max_depth=4,\n",
    "        min_child_weight=5,\n",
    "        seed=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.3,\n",
    "        gamma=0.5,\n",
    "        reg_alpha=3,\n",
    "        reg_lambda=1,\n",
    "        metrics='logloss')\n",
    "\n",
    "    optimized_GBM = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=cv_params,\n",
    "        scoring='neg_log_loss',\n",
    "        cv=5,\n",
    "        verbose=1,\n",
    "        n_jobs=4)\n",
    "\n",
    "    optimized_GBM.fit(X_train, Y_train)\n",
    "    evalute_result = optimized_GBM.grid_scores_\n",
    "    print('每轮迭代运行结果:{0}'.format(evalute_result))\n",
    "    print('参数的最佳取值：{0}'.format(optimized_GBM.best_params_))\n",
    "    print('最佳模型得分:{0}'.format(optimized_GBM.best_score_))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_cv(vecs[:n_train], train['y'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
